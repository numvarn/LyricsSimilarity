{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gensim Doc2Vec\n",
    "\n",
    "สำหรับสร้างโมเดลสำหรับการอกสารที่มีความคล้ายคลึงกัน (Document Similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import os\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Read All Documents \n",
    "'''\n",
    "path = \"./data/05.lyrics_processed_final.csv\"\n",
    "data = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Display Sample of Documents\n",
    "'''\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Display Documents Info.\n",
    "'''\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### นำเฉพาะบางส่วนของเอกสารมาใช้สำหรับสร้างโมเดล"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Use only some past of document (Hook)\n",
    "'''\n",
    "documents = data[\"lyrics_all_processed\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### แปลงเอกสารให้กลายเป็น Train Corpus ด้วย Doc2Vec - TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Convert Documents to Train Corpus by Using Gensim Doc2Vec\n",
    "'''\n",
    "train_corpus = []\n",
    "i = 1\n",
    "for doc in documents:\n",
    "    train_corpus.append(gensim.models.doc2vec.TaggedDocument(doc.split(\"|\"), [i]))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### สร้าง Doc2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create Doc2Vec Model\n",
    "'''\n",
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=200, min_count=2, epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create Vocabulary\n",
    "'''\n",
    "model.build_vocab(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Train model with train corpus\n",
    "'''\n",
    "model.train(train_corpus, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ทดสอบโมเดลครั้งที่ 1. หาเอกสารที่มีความคล้ายคลึงกับทุกเอกสารภายใน Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Find Similarity of earch documents\n",
    "'''\n",
    "ranks = []\n",
    "second_ranks = []\n",
    "\n",
    "for doc_id in range(len(train_corpus)):\n",
    "    inferred_vector = model.infer_vector(train_corpus[doc_id].words)\n",
    "    \n",
    "    sims = model.docvecs.most_similar([inferred_vector], topn=len(model.docvecs))\n",
    "    \n",
    "    rank = [docid for docid, sim in sims].index(doc_id)\n",
    "    \n",
    "    ranks.append(rank)\n",
    "    \n",
    "    second_ranks.append(sims[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ทดสอบโมเดลครั้งที่ 2. หาเอกสารที่มีความคล้ายคลึงกับเอกสารสุดท้ายใน Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Test the model !!\n",
    "By find similarity of last document\n",
    "'''\n",
    "\n",
    "print('Document ({}): «{}»\\n'.format(doc_id, ''.join(train_corpus[doc_id].words)))\n",
    "\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model)\n",
    "\n",
    "for label, index in [('MOST', 0), ('SECOND-MOST', 1), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:\n",
    "    print(u'%s %s: «%s»\\n' % (label, sims[index], ''.join(train_corpus[sims[index][0]].words)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ทดสอบโมเดลครั้งที่ 3. หาเอกสารที่มีความคล้ายคลึงกับเอกสารที่ถูกสุ่มขึ้นมา"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Test the model !!\n",
    "By find similarity of radcom id document\n",
    "Pick a random document from the corpus and infer a vector from the model\n",
    "'''\n",
    "doc_id = random.randint(0, len(train_corpus) - 1)\n",
    "\n",
    "# Compare and print the second-most-similar document\n",
    "print('Train Document ({}): «{}»\\n'.format(doc_id, ''.join(train_corpus[doc_id].words)))\n",
    "\n",
    "sim_id = second_ranks[doc_id]\n",
    "\n",
    "print('Similar Document {}: «{}»\\n'.format(sim_id, ''.join(train_corpus[sim_id[0]].words)))\n",
    "\n",
    "# ---------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ทดสอบโมเดลครั้งที่ 4. หาเอกสารที่มีความคล้ายคลึงกับ input document\n",
    "\n",
    "1. รับเอกสารเข้ามา\n",
    "1. ทำการแปลงเอกสารที่รับเข้ามาให้อยู่ในรูปแบบของ Infer_vector\n",
    "1. นำเอา Infer_vector ไปทำการค้นหาความคล้ายกับ Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Test the model !!\n",
    "By get input document and transform it into infer vector\n",
    "'''\n",
    "\n",
    "doc_input = 'ขอ|พึ่ง|แรง|แห่ง|ฝัน|บันดาล|ให้|เจอ|คนดี|ให้|สาว|ไกล|บ้าน|คน|นี้|ได้|มี|คน|คอย|ปลอบ|เหงา|งาน|ยุ่ง|เมือง|ใหญ่|ขอ|ใจ|ฮัก|มั่น|กัน|หนาว|นำพา|ใน|ทุก|เรื่องราว|ให้|สาว|ดอก|หญ้า|อุ่นใจ'\n",
    "\n",
    "# ตัดทอน Tokens บางตัวออกไป\n",
    "# doc_input = 'ขอ|พึ่ง|แรง|แห่ง|ฝัน|ให้|เจอ|คนดี|ให้|สาว|คน|นี้|ได้|มี|คน|คอย|ปลอบ|เหงา|เมือง|ใหญ่|ขอ|ใจ|ฮัก|มั่น|กัน|หนาว|นำพา|ใน|ทุก|เรื่องราว|ให้|สาว|ดอก|หญ้า|อุ่นใจ'\n",
    "\n",
    "test_vec = doc_input.split(\"|\")\n",
    "\n",
    "inferred_vector = model.infer_vector(test_vec)\n",
    "\n",
    "sims = model.docvecs.most_similar([inferred_vector], topn=len(model.docvecs))\n",
    "\n",
    "# Compare and print the most/median/least similar documents from the train corpus\n",
    "print('Test Document: «{}»\\n'.format(' '.join(test_vec)))\n",
    "\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model)\n",
    "for label, index in [('MOST', 0), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:\n",
    "    print(u'%s %s: «%s»\\n' % (label, sims[index], ''.join(train_corpus[sims[index][0]].words)))\n",
    "\n",
    "# ---------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### บันทึกโมเดลเพื่อนำไปใช้งานต่อไป"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Save the Doc2Vec model\n",
    "'''\n",
    "model.save('./model/model_docvec.d2v')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}